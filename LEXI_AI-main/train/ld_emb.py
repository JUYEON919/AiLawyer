import os
import json
import chromadb
import torch
from transformers import AutoModel, AutoTokenizer

# âœ… ë°ì´í„° ê²½ë¡œ ì„¤ì •
JSON_PATH = os.path.abspath("../dataset/íŒë¡€ëª©ë¡.json")

# âœ… GPU ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"

# âœ… ChromaDB ì„¤ì •
CHROMA_DB_PATH = "../dataset/chroma_db"
chroma_client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
legal_precedents_collection = chroma_client.get_or_create_collection(name="legal_precedents")

# âœ… Fine-tuned `legal-bert-base` ëª¨ë¸ ë¡œë“œ
MODEL_PATH = "../ft_legal_bert/checkpoint-1185"
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
embedding_model = AutoModel.from_pretrained(MODEL_PATH).to(device)

def embed_text(text):
    """ âœ… Fine-tuned ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ì„ ë²¡í„°í™” (GPU í™œìš©) """
    if not isinstance(text, str) or not text.strip():
        return None  # ë¹ˆ ë¬¸ìì—´ ë˜ëŠ” None ê°’ ë°©ì§€

    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding="max_length", max_length=512).to(device)
    
    with torch.no_grad():
        outputs = embedding_model(**inputs)
    
    return outputs.last_hidden_state[:, 0, :].cpu().numpy().tolist()[0]  # 1ì°¨ì› ë¦¬ìŠ¤íŠ¸ ë³€í™˜

def process_precedents():
    """ âœ… íŒë¡€ ëª©ë¡ ë°ì´í„° ì²˜ë¦¬ ë° ì„ë² ë”© """
    with open(JSON_PATH, "r", encoding="utf-8") as f:
        precedents_data = json.load(f)

    for data in precedents_data:
        case_number = data.get("ì‚¬ê±´ë²ˆí˜¸", "").strip()
        title = data.get("ì œëª©", "").strip()
        ruling = data.get("íŒì‹œì‚¬í•­", "").strip()

        # âœ… ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        if not case_number or not title or not ruling:
            print(f"âš  ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ê±´ë„ˆëœ€: ì‚¬ê±´ë²ˆí˜¸ {case_number}")
            continue

        # âœ… íŒë¡€ ë°ì´í„° í¬ë§· êµ¬ì„±
        text_data = f"""
        ğŸ“Œ ì‚¬ê±´ë²ˆí˜¸: {case_number}
        ğŸ“Œ ì œëª©: {title}
        ğŸ“Œ íŒì‹œì‚¬í•­:
        {ruling}
        """.strip()

        # âœ… ë²¡í„°í™” ìˆ˜í–‰
        embedding = embed_text(text_data)
        if embedding is None:
            print(f"âš  ì„ë² ë”© ì‹¤íŒ¨ë¡œ ê±´ë„ˆëœ€: ì‚¬ê±´ë²ˆí˜¸ {case_number}")
            continue

        # âœ… ê¸°ì¡´ ë°ì´í„° ì¤‘ë³µ í™•ì¸
        existing_data = legal_precedents_collection.get(ids=[case_number])
        if existing_data and existing_data["ids"]:
            print(f"ğŸ”„ ê¸°ì¡´ ë°ì´í„° ìŠ¤í‚µ: ì‚¬ê±´ë²ˆí˜¸ {case_number}")
            continue

        # âœ… ChromaDBì— ì €ì¥
        print(f"âœ… íŒë¡€ ì¶”ê°€ ì™„ë£Œ: ì‚¬ê±´ë²ˆí˜¸ {case_number}")
        legal_precedents_collection.add(
            ids=[case_number],
            embeddings=[embedding],
            metadatas=[{
                "case_number": case_number,  # âœ… ì‚¬ê±´ë²ˆí˜¸ ì €ì¥
                "title": title,  # âœ… ì œëª© ì €ì¥
                "text": text_data  # âœ… ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥
            }]
        )

if __name__ == "__main__":
    print("ğŸ“Œ íŒë¡€ ëª©ë¡ ë°ì´í„° ë²¡í„°í™” ì‹œì‘...")
    process_precedents()
    print("âœ… ëª¨ë“  íŒë¡€ ëª©ë¡ ë°ì´í„° ë²¡í„°í™” ì™„ë£Œ!")
